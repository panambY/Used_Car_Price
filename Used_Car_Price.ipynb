{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:18:47.244825Z",
     "start_time": "2020-07-28T00:18:45.306768Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display  import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:18:47.256682Z",
     "start_time": "2020-07-28T00:18:47.246676Z"
    }
   },
   "outputs": [],
   "source": [
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:18:47.271611Z",
     "start_time": "2020-07-28T00:18:47.257646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:19:05.508912Z",
     "start_time": "2020-07-28T00:18:47.272606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Whats is low_memory?\n",
    "df_raw = pd.read_csv('data/vehicles.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:19:05.537467Z",
     "start_time": "2020-07-28T00:19:05.509875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>vin</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409586</th>\n",
       "      <td>7111829149</td>\n",
       "      <td>https://buffalo.craigslist.org/cto/d/depew-201...</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>https://buffalo.craigslist.org</td>\n",
       "      <td>4500</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>tiguan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://images.craigslist.org/00707_8BOKosz63r...</td>\n",
       "      <td>2011 black Tiguan, 95k miles. Contact for more...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ny</td>\n",
       "      <td>42.905</td>\n",
       "      <td>-78.7041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                                url   region                      region_url  price    year manufacturer   model condition cylinders fuel  odometer title_status transmission  vin drive size type paint_color                                          image_url                                        description  county state     lat     long\n",
       "409586  7111829149  https://buffalo.craigslist.org/cto/d/depew-201...  buffalo  https://buffalo.craigslist.org   4500  2011.0   volkswagen  tiguan       NaN       NaN  gas       NaN        clean    automatic  NaN   NaN  NaN  NaN         NaN  https://images.craigslist.org/00707_8BOKosz63r...  2011 black Tiguan, 95k miles. Contact for more...     NaN    ny  42.905 -78.7041"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 STEP 01 - DESCRIPTION OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:19:05.590290Z",
     "start_time": "2020-07-28T00:19:05.538429Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:19:05.595280Z",
     "start_time": "2020-07-28T00:19:05.591288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'url', 'region', 'region_url', 'price', 'year', 'manufacturer',\n",
       "       'model', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status',\n",
       "       'transmission', 'vin', 'drive', 'size', 'type', 'paint_color',\n",
       "       'image_url', 'description', 'county', 'state', 'lat', 'long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns\n",
    "\n",
    "# The columns already have a label that I want and easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:19:05.603257Z",
     "start_time": "2020-07-28T00:19:05.596277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 435849\n",
      "Number of Cols: 25\n"
     ]
    }
   ],
   "source": [
    "print( 'Number of Rows: {}'.format( df1.shape[0] ) )\n",
    "print( 'Number of Cols: {}'.format( df1.shape[1] ) )\n",
    "# Evaluate the possibilite do use this project in your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:19:05.616221Z",
     "start_time": "2020-07-28T00:19:05.604255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "url              object\n",
       "region           object\n",
       "region_url       object\n",
       "price             int64\n",
       "year            float64\n",
       "manufacturer     object\n",
       "model            object\n",
       "condition        object\n",
       "cylinders        object\n",
       "fuel             object\n",
       "odometer        float64\n",
       "title_status     object\n",
       "transmission     object\n",
       "vin              object\n",
       "drive            object\n",
       "size             object\n",
       "type             object\n",
       "paint_color      object\n",
       "image_url        object\n",
       "description      object\n",
       "county          float64\n",
       "state            object\n",
       "lat             float64\n",
       "long            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes\n",
    "# At first, the types of the variables are corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:19:05.896005Z",
     "start_time": "2020-07-28T00:19:05.617219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "url                  0\n",
       "region               0\n",
       "region_url           0\n",
       "price                0\n",
       "year              1117\n",
       "manufacturer     20747\n",
       "model             6199\n",
       "condition       186806\n",
       "cylinders       166384\n",
       "fuel              2991\n",
       "odometer         75148\n",
       "title_status      1806\n",
       "transmission      2146\n",
       "vin             196652\n",
       "drive           122011\n",
       "size            295961\n",
       "type            117108\n",
       "paint_color     135247\n",
       "image_url           24\n",
       "description         27\n",
       "county          435849\n",
       "state                0\n",
       "lat               8235\n",
       "long              8235\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:24:48.367049Z",
     "start_time": "2020-07-28T00:19:05.896965Z"
    }
   },
   "outputs": [],
   "source": [
    "# --> year\n",
    "\n",
    "# The first variable that has an empty value and that I will deal with is the \"year\".\n",
    "# Looking at the other variables to be able to see if I can extract some info that helps to fill in the \"nan\" values, I find that the \"description\" column has the info year inside it.\n",
    "# The problem is that there are also \"nan\" values in the \"description\" column. The positive info is that there are only 27 empty values in the \"description\" column.\n",
    "# I only looked at the observations where \"description\" is empty and found that, of the 27 empty values, 3 already have the \"year\" column filled in and the rest have almost no value filled in the other columns.\n",
    "# My solution is as follows: fill the column \"year\" with the information contained in the column \"description\" not empty and drop the entire line in the 24 observations where the column \"description\" is empty along with several others, as we will not have enough info.\n",
    "# First of all, I will drop the rows where the columns \"year\" and \"description\" are null.\n",
    "df1.dropna(subset=['year', 'description'], how='all', inplace=True)\n",
    "df1['year'] = df1.apply( lambda x: x['description'][:5] if math.isnan( x['year'] ) else x['year'], axis=1 )\n",
    "# After fill the nan values in \"year\" column, there are some values that aren't year values, such as: '92 to', '03 je', 'Auto' and 'Nice'. I will transform these values by hand.\n",
    "df1['year'] = df1.apply( lambda x: 1992 if x['year']=='92 to' else x['year'], axis=1 ) # We can see easily that the year is \"1992\"\n",
    "df1['year'] = df1.apply( lambda x: 2003 if x['year']=='03 je' else x['year'], axis=1 ) # We can see easily that the year is \"2003\"\n",
    "df1.drop(df1.loc[df1['year']=='Auto '].index, inplace=True) # In the description columns don't have any info about the year; so, we will drop the entire row.\n",
    "df1.drop(df1.loc[df1['year']=='Nice '].index, inplace=True) # In the description columns don't have any info about the year; so, we will drop the entire row.\n",
    "\n",
    "# --> manufacturer\n",
    "\n",
    "# I noticed that the \"description\" and \"model\" columns have info that can help me fill in the \"manufacturer\" column.\n",
    "# How to get the info from the \"description\" column will be more work at first, I'll try to do a \"to\" from the \"model\" column to fill in the \"manufacturer\" column.\n",
    "df1['model'] = df1['model'].str.lower() # First I will apply a lower function in the \"model\" column.\n",
    "# In the first cicle I will drop que rows that have 'model' and 'manufacturer' with nan values at the same time.\n",
    "df1.drop( index=df1[df1['manufacturer'].isna() & df1['model'].isna()].index, inplace=True )\n",
    "# Now I will create a dictionary with the model and its respective manufacturer.\n",
    "df11 = df1[df1['manufacturer'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "manufacturer_dict = {}\n",
    "for k, v in df12[['model', 'manufacturer']].values:\n",
    "    manufacturer_dict[k] = v\n",
    "df1['manufacturer'] = df1.apply( lambda x: manufacturer_dict[x['model']] if x['model'] in manufacturer_dict.keys() else x['manufacturer'], axis=1) # reduce the \"nan\" values to 17848, but not resolved.\n",
    "# The second attempt to decrease or end \"nan\" values will be to take the list of manufacturers and check if they are present in the \"description\" column.\n",
    "df1['description'] = df1['description'].str.lower()\n",
    "df1['manufacturer'] = df1.apply( lambda x: x['manufacturer'] if pd.isna( x['description'] ) or pd.notna( x['manufacturer'] )\n",
    "                                else 'ford' if 'ford' in str(x['description']).split() \n",
    "                                else 'chevrolet' if 'chevrolet' in str(x['description']).split() \n",
    "                                else 'toyota' if 'toyota' in str(x['description']).split() \n",
    "                                else 'nissan' if 'nissan' in str(x['description']).split() \n",
    "                                else 'honda' if 'honda' in str(x['description']).split()\n",
    "                                else 'jeep' if 'jeep' in str(x['description']).split() \n",
    "                                else 'gmc' if 'gmc' in str(x['description']).split() \n",
    "                                else 'ram' if 'ram' in str(x['description']).split() \n",
    "                                else 'dodge' if 'dodge' in str(x['description']).split() \n",
    "                                else 'mercedes-benz' if 'mercedes-benz' in str(x['description']).split() \n",
    "                                else 'bmw' if 'bmw' in str(x['description']).split() \n",
    "                                else 'hyundau' if 'hyundai' in str(x['description']).split() \n",
    "                                else 'subaru' if 'subaru' in str(x['description']).split() \n",
    "                                else 'volkswagen' if 'volkswagen' in str(x['description']).split() \n",
    "                                else 'kia' if 'kia' in str(x['description']).split()\n",
    "                                else 'chrysler' if 'chrysler' in str(x['description']).split() \n",
    "                                else 'cadillac' if 'cadillac' in str(x['description']).split() \n",
    "                                else 'lexus' if 'lexus' in str(x['description']).split() \n",
    "                                else 'buick' if 'buick' in str(x['description']).split() \n",
    "                                else 'mazda' if 'mazda' in str(x['description']).split()\n",
    "                                else 'audi' if 'audi' in str(x['description']).split() \n",
    "                                else 'acura' if 'acura' in str(x['description']).split() \n",
    "                                else 'infiniti' if 'infiniti' in str(x['description']).split() \n",
    "                                else 'lincoln' if 'lincoln' in str(x['description']).split() \n",
    "                                else 'pontiac' if 'pontiac' in str(x['description']).split()\n",
    "                                else 'volvo' if 'volvo' in str(x['description']).split() \n",
    "                                else 'mitsubishi' if 'mitsubishi' in str(x['description']).split() \n",
    "                                else 'mini' if 'mini' in str(x['description']).split() \n",
    "                                else 'rover' if 'rover' in str(x['description']).split() \n",
    "                                else 'mercury' if 'mercury' in str(x['description']).split() \n",
    "                                else 'saturn' if 'saturn' in str(x['description']).split() \n",
    "                                else 'fiat' if 'fiat' in str(x['description']).split() \n",
    "                                else 'jaguar' if 'jaguar' in str(x['description']).split() \n",
    "                                else 'tesla' if 'tesla' in str(x['description']).split() \n",
    "                                else 'harley-davidson' if 'harley-davidson' in str(x['description']).split()\n",
    "                                else 'ferrari' if 'ferrari' in str(x['description']).split() \n",
    "                                else 'alfa-romeo' if 'alfa-romeo' in str(x['description']).split() \n",
    "                                else 'datsun' if 'datsun' in str(x['description']).split() \n",
    "                                else 'aston-martin' if 'aston-martin' in str(x['description']).split() \n",
    "                                else 'porche' if 'porche' in str(x['description']).split()\n",
    "                                else 'land rover' if 'land rover' in str(x['description']).split() \n",
    "                                else 'morgan' if 'morgan' in str(x['description']).split()\n",
    "                                else x['manufacturer'], axis=1 ) # reduce the \"nan\" values to 12514, but not resolved.\n",
    "# The third and last attempt I will see the values in \"model\" columns and find a relationtionship between \"manufacturer\" and \"model\".\n",
    "df1['manufacturer'] = df1.apply( lambda x: x['manufacturer'] if pd.isna( x['model'] ) or pd.notna( x['manufacturer'] )\n",
    "                                else 'gmc' if 'hummer' in str(x['model']).split() \n",
    "                                else 'ford' if 'freightliner' in str(x['model']).split() \n",
    "                                else 'volkswagen' if 'porsche' in str(x['model']).split() \n",
    "                                else 'isuzu' if 'isuzu' in str(x['model']).split() \n",
    "                                else 'navistar' if 'internacional ' in str(x['model']).split() \n",
    "                                else 'gmc' if 'saab' in str(x['model']).split() \n",
    "                                else 'suzuki' if 'suzuki' in str(x['model']).split() \n",
    "                                else 'paccar' if 'peterbilt' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'jetta' in str(x['model']).split()\n",
    "                                else 'paccar' if 'kenworth' in str(x['model']).split()\n",
    "                                else 'chrysler' if 'plymouth' in str(x['model']).split()\n",
    "                                else 'gmc' if 'oldsmobile' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'bentley' in str(x['model']).split()\n",
    "                                else 'toyota' if 'hino' in str(x['model']).split()\n",
    "                                else 'gmc' if 'janesville' in str(x['model']).split()\n",
    "                                else 'bmw' if 'triumph' in str(x['model']).split()\n",
    "                                else 'chrysler' if 'maserati' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'lamborghini' in str(x['model']).split()\n",
    "                                else 'chevrolet' if 'corvette' in str(x['model']).split()\n",
    "                                else 'gmc' if 'caddilac' in str(x['model']).split()\n",
    "                                else 'chevrolet' if 'cheverolet' in str(x['model']).split()\n",
    "                                else 'hyundau' if 'hyunday' in str(x['model']).split()\n",
    "                                else 'hyundau' if 'hyundai' in str(x['model']).split()\n",
    "                                else 'chevrolet' if 'chevorlet' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'volkswagon' in str(x['model']).split()\n",
    "                                else x['manufacturer'], axis=1 ) # reduce the \"nan\" values to 6068, but not resolved. Thats enought for the first cicle. From the second cycle I can treat data better.\n",
    "# In the rest of the values in \"manufacturer\" column I will input a 'unknown' value.\n",
    "df1['manufacturer'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> condition\n",
    "\n",
    "# Check if you have a model with the \"condition\" filled in that can help us complete the \"nan\" values that have the same model.\n",
    "df11 = df1[df1['condition'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "condition_dict = {}\n",
    "for k, v in df12[['model', 'condition']].values:\n",
    "    condition_dict[k] = v\n",
    "df1['condition'] = df1.apply( lambda x: x['condition'] if pd.isna( x['model'] ) or pd.notna( x['condition'] ) else condition_dict[x['model']] if x['model'] in condition_dict.keys() else x['condition'], axis=1)# 28615 \"nan\" values left.\n",
    "# as it can cause confusion between the \"like new\" and \"new\" values I will not try to fill in the \"nan\" values using the ifo's in the \"description\" variable.\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['condition'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> cylinders\n",
    "\n",
    "# Check if you have a model with the \"cylinders\" filled in that can help us complete the \"nan\" values that have the same model.\n",
    "df11 = df1[df1['cylinders'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "cylinders_dict = {}\n",
    "for k, v in df12[['model', 'cylinders']].values:\n",
    "    cylinders_dict[k] = v\n",
    "df1['cylinders'] = df1.apply( lambda x: x['cylinders'] if pd.isna( x['model'] ) or pd.notna( x['cylinders'] ) else cylinders_dict[x['model']] if x['model'] in cylinders_dict.keys() else x['cylinders'], axis=1)# 29022 \"nan\" values remain.\n",
    "# Since the values inside the \"cylinders\" variable have space between them, they can cause errors in filling in the \"nan\" values using the \"split\" function.\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['cylinders'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> fuel\n",
    "\n",
    "# As it can happen that the same car model has several possibilities for \"fuel\" I will not use the search formula in the \"model\" variable.\n",
    "# Check and there is a \"fuel\" value within the \"description\" variable. In order not to cause an error in filling in the \"nan\" values, I will not use the \"other\" value.\n",
    "df1['fuel'] = df1.apply( lambda x: x['fuel'] if pd.isna( x['description'] ) or pd.notna( x['fuel'] )\n",
    "                                else 'gas' if 'gas' in str(x['description']).split() \n",
    "                                else 'diesel' if 'diesel' in str(x['description']).split() \n",
    "                                else 'hybrid' if 'hybrid' in str(x['description']).split() \n",
    "                                else 'electric' if 'electric' in str(x['description']).split()\n",
    "                                else x['fuel'], axis=1 ) # 2152 \"nan\" values left.\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['fuel'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> odometer\n",
    "\n",
    "# Trying to stipulate the value as close to reality as possible, I will fill in the \"nan\" values by separating this variable by the \"year\" column and calculating the median to try to prevent the value from being affected by possible outliers.\n",
    "df1['odometer'] = df1['odometer'].fillna(df1.groupby('year')['odometer'].transform('median'))\n",
    "# Since there are only 40 empty values left, I will drop all 40 lines that have \"nan\" values in the \"odometer\" column.\n",
    "df1.drop(df1[df1['odometer'].isna()].index, inplace=True)\n",
    "\n",
    "# --> title_status\n",
    "\n",
    "# Since the values of this variable are difficult to identify effectively through queries to other columns and the total \"nan\" values are low, I will directly fill in the \"nan\" values with \"unknown\".\n",
    "df1['title_status'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> transmission\n",
    "\n",
    "# As it can happen that the same car model has several transmission possibilities, I will not use the search formula in the variable \"model\".\n",
    "# Check and there is the value of \"transmission\" inside the variable \"description\". In order not to cause an error in filling in the \"nan\" values, I will not use the \"other\" value.\n",
    "df1['transmission'] = df1.apply( lambda x: x['transmission'] if pd.isna( x['description'] ) or pd.notna( x['transmission'] )\n",
    "                                else 'automatic' if 'automatic' in str(x['description']).split() \n",
    "                                else 'manual' if 'manual' in str(x['description']).split()\n",
    "                                else x['transmission'], axis=1 ) # 1812 \"nan\" values remain.\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['transmission'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> drive\n",
    "\n",
    "# Check if you have a model with the \"drive\" filled in that can help us complete the \"nan\" values that have the same model.\n",
    "df11 = df1[df1['drive'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "drive_dict = {}\n",
    "for k, v in df12[['model', 'drive']].values:\n",
    "    drive_dict[k] = v\n",
    "df1['size'] = df1.apply( lambda x: x['drive'] if pd.isna( x['model'] ) or pd.notna( x['drive'] ) else drive_dict[x['model']] if x['model'] in drive_dict.keys() else x['drive'], axis=1)# 18125 \"nan\" values remain.\n",
    "# Check and there is a \"drive\" value inside the \"description\" variable.\n",
    "df1['drive'] = df1.apply( lambda x: x['drive'] if pd.isna( x['description'] ) or pd.notna( x['drive'] )\n",
    "                                else '4wd' if '4wd' in str(x['description']).split() \n",
    "                                else 'fwd' if 'fwd' in str(x['description']).split() \n",
    "                                else 'rwd' if 'rwd' in str(x['description']).split() \n",
    "                                else x['drive'], axis=1 ) # did not fill in any \"nan\" values.\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['drive'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> size\n",
    "\n",
    "# Check if you have a model with the \"size\" filled in that can help us complete the \"nan\" values that have the same model.\n",
    "df11 = df1[df1['size'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "size_dict = {}\n",
    "for k, v in df12[['model', 'size']].values:\n",
    "    size_dict[k] = v\n",
    "df1['size'] = df1.apply( lambda x: x['size'] if pd.isna( x['model'] ) or pd.notna( x['size'] ) else size_dict[x['model']] if x['model'] in size_dict.keys() else x['size'], axis=1)\n",
    "# Check and there is a \"size\" value inside the \"description\" variable.\n",
    "df1['size'] = df1.apply( lambda x: x['size'] if pd.isna( x['description'] ) or pd.notna( x['size'] )\n",
    "                                else 'full-size' if 'full-size' in str(x['description']).split() \n",
    "                                else 'mid-size' if 'mid-size' in str(x['description']).split() \n",
    "                                else 'compact' if 'compact' in str(x['description']).split() \n",
    "                                else 'sub-compact' if 'sub-compact' in str(x['description']).split() \n",
    "                                else x['size'], axis=1 )\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['size'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> type\n",
    "\n",
    "# Check if you have a model with the \"type\" filled in that can help us complete the \"nan\" values that have the same model.\n",
    "df11 = df1[df1['type'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "type_dict = {}\n",
    "for k, v in df12[['model', 'type']].values:\n",
    "    type_dict[k] = v\n",
    "df1['type'] = df1.apply( lambda x: x['type'] if pd.isna( x['model'] ) or pd.notna( x['type'] ) else type_dict[x['model']] if x['model'] in type_dict.keys() else x['type'], axis=1)# 17472 \"nan\" values remain.\n",
    "# Check and there is the value of \"type\" inside the variable \"description\".\n",
    "df1['type'] = df1.apply( lambda x: x['type'] if pd.isna( x['description'] ) or pd.notna( x['type'] )\n",
    "                                else 'SUV' if 'SUV' in str(x['description']).split() \n",
    "                                else 'sedan' if 'sedan' in str(x['description']).split() \n",
    "                                else 'pickup' if 'pickup' in str(x['description']).split() \n",
    "                                else 'truck' if 'truck' in str(x['description']).split() \n",
    "                                else 'coupe' if 'coupe ' in str(x['description']).split() \n",
    "                                else 'hatchback' if 'hatchback' in str(x['description']).split() \n",
    "                                else 'van' if 'van' in str(x['description']).split() \n",
    "                                else 'wagon' if 'wagon' in str(x['description']).split()\n",
    "                                else 'convertible' if 'convertible' in str(x['description']).split()\n",
    "                                else 'mini-van' if 'mini-van' in str(x['description']).split()\n",
    "                                else 'offroad' if 'offroad' in str(x['description']).split()\n",
    "                                else 'bus' if 'bus' in str(x['description']).split()\n",
    "                                else x['type'], axis=1 )# 10685 \"nan\" values left.\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['type'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> paint-color\n",
    "\n",
    "# As it can happen that the same car model has several possibilities of \"paint-color\" I will not use the search formula in the variable \"model\".\n",
    "# Check and there is the value of \"paint-color\" inside the variable \"description\".\n",
    "df1['paint_color'] = df1.apply( lambda x: x['paint_color'] if pd.isna( x['description'] ) or pd.notna( x['paint_color'] )\n",
    "                                else 'white' if 'white' in str(x['description']).split() \n",
    "                                else 'black' if 'black' in str(x['description']).split() \n",
    "                                else 'silver' if 'silver' in str(x['description']).split() \n",
    "                                else 'blue' if 'blue' in str(x['description']).split() \n",
    "                                else 'grey' if 'grey ' in str(x['description']).split() \n",
    "                                else 'red' if 'red' in str(x['description']).split() \n",
    "                                else 'green' if 'green' in str(x['description']).split() \n",
    "                                else 'custom' if 'custom' in str(x['description']).split()\n",
    "                                else 'brown' if 'brown' in str(x['description']).split()\n",
    "                                else 'yellow' if 'yellow' in str(x['description']).split()\n",
    "                                else 'orange' if 'orange' in str(x['description']).split()\n",
    "                                else 'purple' if 'purple' in str(x['description']).split()\n",
    "                                else x['paint_color'], axis=1 ) # 89241 \"nan\" values left.\n",
    "# For the remaining \"nan\" values, enter the \"unknown\" value.\n",
    "df1['paint_color'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> lat and long\n",
    "\n",
    "# Since \"lat\" and \"long\" are directly related to \"region\" I will separate them by \"region\" and average \"lat\" and \"long\".\n",
    "# Here, unlike what was done in the \"odometer\" variable, there is no need to use the median because the variation in this case will be very small.\n",
    "df1['lat'] = df1['lat'].fillna(df1.groupby('region')['lat'].transform('mean'))\n",
    "df1['long'] = df1['long'].fillna(df1.groupby('region')['long'].transform('mean')) # no missing values left.\n",
    "\n",
    "# --> id\n",
    "\n",
    "# This variable is not relevant to the project. So I will not deal with your \"nan\" values and I will drop this column.\n",
    "df1.drop( ['id'], axis=1, inplace=True )\n",
    "\n",
    "# --> url\n",
    "\n",
    "# This variable is not relevant to the project. So I will not deal with your \"nan\" values and I will drop this column.\n",
    "df1.drop( ['url'], axis=1, inplace=True )\n",
    "\n",
    "# --> region_url\n",
    "\n",
    "# This variable is not relevant to the project. So I will not deal with your \"nan\" values and I will drop this column.\n",
    "df1.drop( ['region_url'], axis=1, inplace=True )\n",
    "\n",
    "# --> model\n",
    "\n",
    "# That column has a lot of polluted data and it would take months of work to try to correct it one by one. As I have a lot of variables with good potentials in this dataset I will choose to drop this column. \n",
    "# If the model does not perform well in the end, in the next cycles I will study the possibility of treating this column better.\n",
    "# I think it is worse for the project to delete only the nan rows, but keeping the column, than to delete the entire column and not decrease the number of observations in our dataset.\n",
    "df1.drop( ['model'], axis=1, inplace=True )\n",
    "\n",
    "# --> vin\n",
    "\n",
    "# This variable is not relevant to the project. So I will not deal with your \"nan\" values and I will drop this column.\n",
    "df1.drop( ['vin'], axis=1, inplace=True )\n",
    "\n",
    "# --> image_url\n",
    "\n",
    "# This variable is not relevant to the project. So I will not deal with your \"nan\" values and I will drop this column.\n",
    "df1.drop( ['image_url'], axis=1, inplace=True )\n",
    "\n",
    "# --> description\n",
    "\n",
    "# This variable is not relevant to the project, but it was extremely important in helping to fill in the \"nan\" values in other columns. So I will not deal with your \"nan\" values and I will drop this column.\n",
    "df1.drop( ['description'], axis=1, inplace=True )\n",
    "\n",
    "# --> county\n",
    "\n",
    "# All the \"county\" column have null value. I will drop this column.\n",
    "df1.drop( ['county'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T00:27:01.202154Z",
     "start_time": "2020-07-28T00:27:01.036030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region          0\n",
       "price           0\n",
       "year            0\n",
       "manufacturer    0\n",
       "condition       0\n",
       "cylinders       0\n",
       "fuel            0\n",
       "odometer        0\n",
       "title_status    0\n",
       "transmission    0\n",
       "drive           0\n",
       "size            0\n",
       "type            0\n",
       "paint_color     0\n",
       "state           0\n",
       "lat             0\n",
       "long            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Change Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
