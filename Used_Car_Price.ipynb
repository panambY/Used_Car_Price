{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:28.992766Z",
     "start_time": "2020-07-27T13:14:27.286644Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display  import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:30.295844Z",
     "start_time": "2020-07-27T13:14:30.286889Z"
    }
   },
   "outputs": [],
   "source": [
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:30.763785Z",
     "start_time": "2020-07-27T13:14:30.749823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:50.921790Z",
     "start_time": "2020-07-27T13:14:32.123146Z"
    }
   },
   "outputs": [],
   "source": [
    "# Whats is low_memory?\n",
    "df_raw = pd.read_csv('data/vehicles.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:50.974587Z",
     "start_time": "2020-07-27T13:14:50.928694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>vin</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183540</th>\n",
       "      <td>7117126746</td>\n",
       "      <td>https://sanantonio.craigslist.org/ctd/d/temple...</td>\n",
       "      <td>san antonio</td>\n",
       "      <td>https://sanantonio.craigslist.org</td>\n",
       "      <td>16999</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>c-hr xle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gas</td>\n",
       "      <td>23882.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://images.craigslist.org/00L0L_5HowwXwFX5...</td>\n",
       "      <td>WWW.TEXASDIESELSTORE.COM  CALL OR TEXT TODAY @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tx</td>\n",
       "      <td>31.071</td>\n",
       "      <td>-97.3898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                                url       region                         region_url  price    year manufacturer     model condition cylinders fuel  odometer title_status transmission  vin drive size type paint_color                                          image_url                                        description  county state     lat     long\n",
       "183540  7117126746  https://sanantonio.craigslist.org/ctd/d/temple...  san antonio  https://sanantonio.craigslist.org  16999  2018.0       toyota  c-hr xle       NaN       NaN  gas   23882.0        clean    automatic  NaN   NaN  NaN  NaN         NaN  https://images.craigslist.org/00L0L_5HowwXwFX5...  WWW.TEXASDIESELSTORE.COM  CALL OR TEXT TODAY @...     NaN    tx  31.071 -97.3898"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 STEP 01 - DESCRIPTION OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T21:55:05.511482Z",
     "start_time": "2020-07-27T21:55:05.442452Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:53.414546Z",
     "start_time": "2020-07-27T13:14:53.410553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'url', 'region', 'region_url', 'price', 'year', 'manufacturer',\n",
       "       'model', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status',\n",
       "       'transmission', 'vin', 'drive', 'size', 'type', 'paint_color',\n",
       "       'image_url', 'description', 'county', 'state', 'lat', 'long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns\n",
    "\n",
    "# The columns already have a label that I want and easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:54.974250Z",
     "start_time": "2020-07-27T13:14:54.969264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 435849\n",
      "Number of Cols: 25\n"
     ]
    }
   ],
   "source": [
    "print( 'Number of Rows: {}'.format( df1.shape[0] ) )\n",
    "print( 'Number of Cols: {}'.format( df1.shape[1] ) )\n",
    "# Evaluate the possibilite do use this project in your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:57.550438Z",
     "start_time": "2020-07-27T13:14:57.543458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "url              object\n",
       "region           object\n",
       "region_url       object\n",
       "price             int64\n",
       "year            float64\n",
       "manufacturer     object\n",
       "model            object\n",
       "condition        object\n",
       "cylinders        object\n",
       "fuel             object\n",
       "odometer        float64\n",
       "title_status     object\n",
       "transmission     object\n",
       "vin              object\n",
       "drive            object\n",
       "size             object\n",
       "type             object\n",
       "paint_color      object\n",
       "image_url        object\n",
       "description      object\n",
       "county          float64\n",
       "state            object\n",
       "lat             float64\n",
       "long            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes\n",
    "# At first, the types of the variables are corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:14:59.193615Z",
     "start_time": "2020-07-27T13:14:58.919350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "url                  0\n",
       "region               0\n",
       "region_url           0\n",
       "price                0\n",
       "year              1117\n",
       "manufacturer     20747\n",
       "model             6199\n",
       "condition       186806\n",
       "cylinders       166384\n",
       "fuel              2991\n",
       "odometer         75148\n",
       "title_status      1806\n",
       "transmission      2146\n",
       "vin             196652\n",
       "drive           122011\n",
       "size            295961\n",
       "type            117108\n",
       "paint_color     135247\n",
       "image_url           24\n",
       "description         27\n",
       "county          435849\n",
       "state                0\n",
       "lat               8235\n",
       "long              8235\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T11:03:45.769674Z",
     "start_time": "2020-07-27T10:58:03.691180Z"
    }
   },
   "outputs": [],
   "source": [
    "# --> year\n",
    "\n",
    "# The first variable that has an empty value and that I will deal with is the \"year\".\n",
    "# Looking at the other variables to be able to see if I can extract some info that helps to fill in the \"nan\" values, I find that the \"description\" column has the info year inside it.\n",
    "# The problem is that there are also \"nan\" values in the \"description\" column. The positive info is that there are only 27 empty values in the \"description\" column.\n",
    "# I only looked at the observations where \"description\" is empty and found that, of the 27 empty values, 3 already have the \"year\" column filled in and the rest have almost no value filled in the other columns.\n",
    "# My solution is as follows: fill the column \"year\" with the information contained in the column \"description\" not empty and drop the entire line in the 24 observations where the column \"description\" is empty along with several others, as we will not have enough info.\n",
    "# First of all, I will drop the rows where the columns \"year\" and \"description\" are null.\n",
    "df1.dropna(subset=['year', 'description'], how='all', inplace=True)\n",
    "df1['year'] = df1.apply( lambda x: x['description'][:5] if math.isnan( x['year'] ) else x['year'], axis=1 )\n",
    "# After fill the nan values in \"year\" column, there are some values that aren't year values, such as: '92 to', '03 je', 'Auto' and 'Nice'. I will transform these values by hand.\n",
    "df1['year'] = df1.apply( lambda x: 1992 if x['year']=='92 to' else x['year'], axis=1 ) # We can see easily that the year is \"1992\"\n",
    "df1['year'] = df1.apply( lambda x: 2003 if x['year']=='03 je' else x['year'], axis=1 ) # We can see easily that the year is \"2003\"\n",
    "df1.drop(df1.loc[df1['year']=='Auto '].index, inplace=True) # In the description columns don't have any info about the year; so, we will drop the entire row.\n",
    "df1.drop(df1.loc[df1['year']=='Nice '].index, inplace=True) # In the description columns don't have any info about the year; so, we will drop the entire row.\n",
    "\n",
    "# --> manufacturer\n",
    "\n",
    "# I noticed that the \"description\" and \"model\" columns have info that can help me fill in the \"manufacturer\" column.\n",
    "# How to get the info from the \"description\" column will be more work at first, I'll try to do a \"to\" from the \"model\" column to fill in the \"manufacturer\" column.\n",
    "df1['model'] = df1['model'].str.lower() # First I will apply a lower function in the \"model\" column.\n",
    "# In the first cicle I will drop que rows that have 'model' and 'manufacturer' with nan values at the same time.\n",
    "df1.drop( index=df1[df1['manufacturer'].isna() & df1['model'].isna()].index, inplace=True )\n",
    "# Now I will create a dictionary with the model and its respective manufacturer.\n",
    "df11 = df1[df1['manufacturer'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "manufacturer_dict = {}\n",
    "for k, v in df12[['model', 'manufacturer']].values:\n",
    "    manufacturer_dict[k] = v\n",
    "df1['manufacturer'] = df1.apply( lambda x: manufacturer_dict[x['model']] if x['model'] in manufacturer_dict.keys() else x['manufacturer'], axis=1) # reduce the \"nan\" values to 17848, but not resolved.\n",
    "# The second attempt to decrease or end \"nan\" values will be to take the list of manufacturers and check if they are present in the \"description\" column.\n",
    "df1['description'] = df1['description'].str.lower()\n",
    "df1['manufacturer'] = df1.apply( lambda x: x['manufacturer'] if pd.isna( x['description'] ) or pd.notna( x['manufacturer'] )\n",
    "                                else 'ford' if 'ford' in str(x['description']).split() \n",
    "                                else 'chevrolet' if 'chevrolet' in str(x['description']).split() \n",
    "                                else 'toyota' if 'toyota' in str(x['description']).split() \n",
    "                                else 'nissan' if 'nissan' in str(x['description']).split() \n",
    "                                else 'honda' if 'honda' in str(x['description']).split()\n",
    "                                else 'jeep' if 'jeep' in str(x['description']).split() \n",
    "                                else 'gmc' if 'gmc' in str(x['description']).split() \n",
    "                                else 'ram' if 'ram' in str(x['description']).split() \n",
    "                                else 'dodge' if 'dodge' in str(x['description']).split() \n",
    "                                else 'mercedes-benz' if 'mercedes-benz' in str(x['description']).split() \n",
    "                                else 'bmw' if 'bmw' in str(x['description']).split() \n",
    "                                else 'hyundau' if 'hyundai' in str(x['description']).split() \n",
    "                                else 'subaru' if 'subaru' in str(x['description']).split() \n",
    "                                else 'volkswagen' if 'volkswagen' in str(x['description']).split() \n",
    "                                else 'kia' if 'kia' in str(x['description']).split()\n",
    "                                else 'chrysler' if 'chrysler' in str(x['description']).split() \n",
    "                                else 'cadillac' if 'cadillac' in str(x['description']).split() \n",
    "                                else 'lexus' if 'lexus' in str(x['description']).split() \n",
    "                                else 'buick' if 'buick' in str(x['description']).split() \n",
    "                                else 'mazda' if 'mazda' in str(x['description']).split()\n",
    "                                else 'audi' if 'audi' in str(x['description']).split() \n",
    "                                else 'acura' if 'acura' in str(x['description']).split() \n",
    "                                else 'infiniti' if 'infiniti' in str(x['description']).split() \n",
    "                                else 'lincoln' if 'lincoln' in str(x['description']).split() \n",
    "                                else 'pontiac' if 'pontiac' in str(x['description']).split()\n",
    "                                else 'volvo' if 'volvo' in str(x['description']).split() \n",
    "                                else 'mitsubishi' if 'mitsubishi' in str(x['description']).split() \n",
    "                                else 'mini' if 'mini' in str(x['description']).split() \n",
    "                                else 'rover' if 'rover' in str(x['description']).split() \n",
    "                                else 'mercury' if 'mercury' in str(x['description']).split() \n",
    "                                else 'saturn' if 'saturn' in str(x['description']).split() \n",
    "                                else 'fiat' if 'fiat' in str(x['description']).split() \n",
    "                                else 'jaguar' if 'jaguar' in str(x['description']).split() \n",
    "                                else 'tesla' if 'tesla' in str(x['description']).split() \n",
    "                                else 'harley-davidson' if 'harley-davidson' in str(x['description']).split()\n",
    "                                else 'ferrari' if 'ferrari' in str(x['description']).split() \n",
    "                                else 'alfa-romeo' if 'alfa-romeo' in str(x['description']).split() \n",
    "                                else 'datsun' if 'datsun' in str(x['description']).split() \n",
    "                                else 'aston-martin' if 'aston-martin' in str(x['description']).split() \n",
    "                                else 'porche' if 'porche' in str(x['description']).split()\n",
    "                                else 'land rover' if 'land rover' in str(x['description']).split() \n",
    "                                else 'morgan' if 'morgan' in str(x['description']).split()\n",
    "                                else x['manufacturer'], axis=1 ) # reduce the \"nan\" values to 12514, but not resolved.\n",
    "# The third and last attempt I will see the values in \"model\" columns and find a relationtionship between \"manufacturer\" and \"model\".\n",
    "df1['manufacturer'] = df1.apply( lambda x: x['manufacturer'] if pd.isna( x['model'] ) or pd.notna( x['manufacturer'] )\n",
    "                                else 'gmc' if 'hummer' in str(x['model']).split() \n",
    "                                else 'ford' if 'freightliner' in str(x['model']).split() \n",
    "                                else 'volkswagen' if 'porsche' in str(x['model']).split() \n",
    "                                else 'isuzu' if 'isuzu' in str(x['model']).split() \n",
    "                                else 'navistar' if 'internacional ' in str(x['model']).split() \n",
    "                                else 'gmc' if 'saab' in str(x['model']).split() \n",
    "                                else 'suzuki' if 'suzuki' in str(x['model']).split() \n",
    "                                else 'paccar' if 'peterbilt' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'jetta' in str(x['model']).split()\n",
    "                                else 'paccar' if 'kenworth' in str(x['model']).split()\n",
    "                                else 'chrysler' if 'plymouth' in str(x['model']).split()\n",
    "                                else 'gmc' if 'oldsmobile' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'bentley' in str(x['model']).split()\n",
    "                                else 'toyota' if 'hino' in str(x['model']).split()\n",
    "                                else 'gmc' if 'janesville' in str(x['model']).split()\n",
    "                                else 'bmw' if 'triumph' in str(x['model']).split()\n",
    "                                else 'chrysler' if 'maserati' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'lamborghini' in str(x['model']).split()\n",
    "                                else 'chevrolet' if 'corvette' in str(x['model']).split()\n",
    "                                else 'gmc' if 'caddilac' in str(x['model']).split()\n",
    "                                else 'chevrolet' if 'cheverolet' in str(x['model']).split()\n",
    "                                else 'hyundau' if 'hyunday' in str(x['model']).split()\n",
    "                                else 'hyundau' if 'hyundai' in str(x['model']).split()\n",
    "                                else 'chevrolet' if 'chevorlet' in str(x['model']).split()\n",
    "                                else 'volkswagen' if 'volkswagon' in str(x['model']).split()\n",
    "                                else x['manufacturer'], axis=1 ) # reduce the \"nan\" values to 6068, but not resolved. Thats enought for the first cicle. From the second cycle I can treat data better.\n",
    "# In the rest of the values in \"manufacturer\" column I will input a 'unknown' value.\n",
    "df1['manufacturer'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> condition\n",
    "# Verificar se tem algum modelo com o \"condition\" preenchido que possa nos ajudar a completar os valores \"nan\" que possuem o mesmo modelo.\n",
    "df11 = df1[df1['condition'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "condition_dict = {}\n",
    "for k, v in df12[['model', 'condition']].values:\n",
    "    condition_dict[k] = v\n",
    "df1['condition'] = df1.apply( lambda x: x['condition'] if pd.isna( x['model'] ) or pd.notna( x['condition'] ) else condition_dict[x['model']] if x['model'] in condition_dict.keys() else x['condition'], axis=1) # sobraram 28615 valores \"nan\".\n",
    "# como pode causar confusão entre os valores \"like new\" e \"new\" eu não vou tentar preencher os valores \"nan\" usando as ifo que estão na variável \"description\".\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['condition'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> cylinders\n",
    "# Verificar se tem algum modelo com o \"cylinders\" preenchido que possa nos ajudar a completar os valores \"nan\" que possuem o mesmo modelo.\n",
    "df11 = df1[df1['cylinders'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "cylinders_dict = {}\n",
    "for k, v in df12[['model', 'cylinders']].values:\n",
    "    cylinders_dict[k] = v\n",
    "df1['cylinders'] = df1.apply( lambda x: x['cylinders'] if pd.isna( x['model'] ) or pd.notna( x['cylinders'] ) else cylinders_dict[x['model']] if x['model'] in cylinders_dict.keys() else x['cylinders'], axis=1) # sobraram 29022 valores \"nan\".\n",
    "# Como os valores dentro da variável \" cylinders\" tem espaço entre eles, podem causar erros no preenchimento dos valores \"nan\" com o uso da função \"split\".\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['cylinders'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> fuel\n",
    "# Como pode acontecer do mesmo modelo de carro ter várias possibilidades de \"fuel\" eu não vou usar a fórmula de pesquisa na variável \"model\".\n",
    "# Verificar ae existe o valor do \"fuel\" dentro da variável \"description\". Para não causar erro de preenchimento dos valores \"nan\" eu não vou usar o valor \"other\".\n",
    "df1['fuel'] = df1.apply( lambda x: x['fuel'] if pd.isna( x['description'] ) or pd.notna( x['fuel'] )\n",
    "                                else 'gas' if 'gas' in str(x['description']).split() \n",
    "                                else 'diesel' if 'diesel' in str(x['description']).split() \n",
    "                                else 'hybrid' if 'hybrid' in str(x['description']).split() \n",
    "                                else 'electric' if 'electric' in str(x['description']).split()\n",
    "                                else x['fuel'], axis=1 ) # sobraram 2152 valores \"nan\".\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['fuel'].fillna( 'unknown', inplace=True )\n",
    "\n",
    "# --> odometer\n",
    "# Tentando estipular o valor mais próximo possível da realidade eu vou preencher os valores \"nan\" separando essa variável pela coluna \"year\" e calculando a mediana para tentar evitar que o valor seja afetado por possíveis outliers.\n",
    "# df1['odometer'].fillna( median('odometer'), inplace=True )\n",
    "\n",
    "# --> title_status\n",
    "# Como os valores dessa variável são difíceis de identificar com eficácia através de consultas à outras colunas e o total de valores \"nan\" são baixos, eu vou preencher direto os valores \"nan\" com \"unknown\".\n",
    "df1['title_status'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> transmission\n",
    "# Como pode acontecer do mesmo modelo de carro ter várias possibilidades de \"transmission\" eu não vou usar a fórmula de pesquisa na variável \"model\".\n",
    "# Verificar ae existe o valor do \"transmission\" dentro da variável \"description\". Para não causar erro de preenchimento dos valores \"nan\" eu não vou usar o valor \"other\".\n",
    "df1['transmission'] = df1.apply( lambda x: x['transmission'] if pd.isna( x['description'] ) or pd.notna( x['transmission'] )\n",
    "                                else 'automatic' if 'automatic' in str(x['description']).split() \n",
    "                                else 'manual' if 'manual' in str(x['description']).split()\n",
    "                                else x['transmission'], axis=1 ) # sobraram 1812 valores \"nan\".\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['transmission'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> drive\n",
    "# Verificar se tem algum modelo com o \"drive\" preenchido que possa nos ajudar a completar os valores \"nan\" que possuem o mesmo modelo.\n",
    "df11 = df1[df1['drive'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "drive_dict = {}\n",
    "for k, v in df12[['model', 'drive']].values:\n",
    "    drive_dict[k] = v\n",
    "df1['size'] = df1.apply( lambda x: x['drive'] if pd.isna( x['model'] ) or pd.notna( x['drive'] ) else drive_dict[x['model']] if x['model'] in drive_dict.keys() else x['drive'], axis=1) # sobraram 18125 valores \"nan\".\n",
    "# Verificar ae existe o valor do \"drive\" dentro da variável \"description\".\n",
    "df1['drive'] = df1.apply( lambda x: x['drive'] if pd.isna( x['description'] ) or pd.notna( x['drive'] )\n",
    "                                else '4wd' if '4wd' in str(x['description']).split() \n",
    "                                else 'fwd' if 'fwd' in str(x['description']).split() \n",
    "                                else 'rwd' if 'rwd' in str(x['description']).split() \n",
    "                                else x['drive'], axis=1 ) # não preencheu nenhum valor \"nan\".\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['drive'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> size\n",
    "# Verificar se tem algum modelo com o \"size\" preenchido que possa nos ajudar a completar os valores \"nan\" que possuem o mesmo modelo.\n",
    "df11 = df1[df1['size'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "size_dict = {}\n",
    "for k, v in df12[['model', 'size']].values:\n",
    "    size_dict[k] = v\n",
    "df1['size'] = df1.apply( lambda x: x['size'] if pd.isna( x['model'] ) or pd.notna( x['size'] ) else size_dict[x['model']] if x['model'] in size_dict.keys() else x['size'], axis=1)\n",
    "# Verificar ae existe o valor do \"size\" dentro da variável \"description\".\n",
    "df1['size'] = df1.apply( lambda x: x['size'] if pd.isna( x['description'] ) or pd.notna( x['size'] )\n",
    "                                else 'full-size' if 'full-size' in str(x['description']).split() \n",
    "                                else 'mid-size' if 'mid-size' in str(x['description']).split() \n",
    "                                else 'compact' if 'compact' in str(x['description']).split() \n",
    "                                else 'sub-compact' if 'sub-compact' in str(x['description']).split() \n",
    "                                else x['size'], axis=1 )\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['size'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> type\n",
    "# Verificar se tem algum modelo com o \"type\" preenchido que possa nos ajudar a completar os valores \"nan\" que possuem o mesmo modelo.\n",
    "df11 = df1[df1['type'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "type_dict = {}\n",
    "for k, v in df12[['model', 'type']].values:\n",
    "    type_dict[k] = v\n",
    "df1['type'] = df1.apply( lambda x: x['type'] if pd.isna( x['model'] ) or pd.notna( x['type'] ) else type_dict[x['model']] if x['model'] in type_dict.keys() else x['type'], axis=1) # sobraram 17472 valores \"nan\".\n",
    "# Verificar ae existe o valor do \"type\" dentro da variável \"description\".\n",
    "df1['type'] = df1.apply( lambda x: x['type'] if pd.isna( x['description'] ) or pd.notna( x['type'] )\n",
    "                                else 'SUV' if 'SUV' in str(x['description']).split() \n",
    "                                else 'sedan' if 'sedan' in str(x['description']).split() \n",
    "                                else 'pickup' if 'pickup' in str(x['description']).split() \n",
    "                                else 'truck' if 'truck' in str(x['description']).split() \n",
    "                                else 'coupe' if 'coupe ' in str(x['description']).split() \n",
    "                                else 'hatchback' if 'hatchback' in str(x['description']).split() \n",
    "                                else 'van' if 'van' in str(x['description']).split() \n",
    "                                else 'wagon' if 'wagon' in str(x['description']).split()\n",
    "                                else 'convertible' if 'convertible' in str(x['description']).split()\n",
    "                                else 'mini-van' if 'mini-van' in str(x['description']).split()\n",
    "                                else 'offroad' if 'offroad' in str(x['description']).split()\n",
    "                                else 'bus' if 'bus' in str(x['description']).split()\n",
    "                                else x['type'], axis=1 ) # sobraram 10685 valores \"nan\".\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['type'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> paint-color\n",
    "# Como pode acontecer do mesmo modelo de carro ter várias possibilidades de \"paint-color\" eu não vou usar a fórmula de pesquisa na variável \"model\".\n",
    "# Verificar ae existe o valor do \"paint-color\" dentro da variável \"description\".\n",
    "df1['paint_color'] = df1.apply( lambda x: x['paint_color'] if pd.isna( x['description'] ) or pd.notna( x['paint_color'] )\n",
    "                                else 'white' if 'white' in str(x['description']).split() \n",
    "                                else 'black' if 'black' in str(x['description']).split() \n",
    "                                else 'silver' if 'silver' in str(x['description']).split() \n",
    "                                else 'blue' if 'blue' in str(x['description']).split() \n",
    "                                else 'grey' if 'grey ' in str(x['description']).split() \n",
    "                                else 'red' if 'red' in str(x['description']).split() \n",
    "                                else 'green' if 'green' in str(x['description']).split() \n",
    "                                else 'custom' if 'custom' in str(x['description']).split()\n",
    "                                else 'brown' if 'brown' in str(x['description']).split()\n",
    "                                else 'yellow' if 'yellow' in str(x['description']).split()\n",
    "                                else 'orange' if 'orange' in str(x['description']).split()\n",
    "                                else 'purple' if 'purple' in str(x['description']).split()\n",
    "                                else x['paint_color'], axis=1 ) # sobraram 89241 valores \"nan\".\n",
    "# Para os valores \"nan\" restantes inputar o valor \"unknown\".\n",
    "df1['paint_color'].fillna( 'unknow', inplace=True )\n",
    "\n",
    "# --> lat and long\n",
    "# Como \"lat\" e \"long\" são diretamente relacionados com \"region\" vou separá-los por \"region\" e calcular a média da \"lat\" e \"long\". \n",
    "# Aqui, diferente do que foi feito na variável \"odometer\", não existe a necessidade de usar a mediana porque a variação neste caso vai ser muito pequena.\n",
    "\n",
    "# --> model\n",
    "# That column has a lot of polluted data and it would take months of work to try to correct it one by one. As I have a lot of variables with good potentials in this dataset I will choose to drop this column. \n",
    "# If the model does not perform well in the end, in the next cycles I will study the possibility of treating this column better.\n",
    "# I think it is worse for the project to delete only the nan rows, but keeping the column, than to delete the entire column and not decrease the number of observations in our dataset.\n",
    "df1.drop( ['model'], axis=1, inplace=True )\n",
    "\n",
    "# --> vin\n",
    "# Essa variável não é relevante para o projeto. Por isso não vou tratrar seus valores \"nan\" e irei dropar essa coluna.\n",
    "df1.drop( ['vin'], axis=1, inplace=True )\n",
    "\n",
    "# --> image_url\n",
    "# Essa variável não é relevante para o projeto. Por isso não vou tratrar seus valores \"nan\" e irei dropar essa coluna.\n",
    "df1.drop( ['image_url'], axis=1, inplace=True )\n",
    "\n",
    "# --> description\n",
    "# Essa variável não é relevante para o projeto, mas foi extremamente importante para ajudar no preenchimento dos valores \"nan\" de outras colunas. Por isso não vou tratrar seus valores \"nan\" e irei dropar essa coluna.\n",
    "df1.drop( ['description'], axis=1, inplace=True )\n",
    "\n",
    "# --> county\n",
    "# All the \"county\" column have null value. I will drop this column.\n",
    "df1.drop( ['county'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T22:45:47.542672Z",
     "start_time": "2020-07-27T22:45:47.511755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white     80078\n",
       "black     59703\n",
       "silver    44681\n",
       "blue      30465\n",
       "grey      30351\n",
       "red       29136\n",
       "green      7579\n",
       "custom     7250\n",
       "brown      6550\n",
       "yellow     2081\n",
       "orange     2007\n",
       "purple      721\n",
       "Name: paint_color, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T22:45:50.568377Z",
     "start_time": "2020-07-27T22:45:50.550425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135247"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['paint_color'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T22:23:48.442798Z",
     "start_time": "2020-07-27T22:23:34.272181Z"
    }
   },
   "outputs": [],
   "source": [
    "df11 = df1[df1['cylinders'].notna()]\n",
    "df12 = df11[df11['model'].notna()]\n",
    "cylinders_dict = {}\n",
    "for k, v in df12[['model', 'cylinders']].values:\n",
    "    cylinders_dict[k] = v\n",
    "df1['cylinders'] = df1.apply( lambda x: x['cylinders'] if pd.isna( x['model'] ) or pd.notna( x['cylinders'] ) else cylinders_dict[x['model']] if x['model'] in cylinders_dict.keys() else x['cylinders'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T22:47:07.808367Z",
     "start_time": "2020-07-27T22:47:07.766482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white     90317\n",
       "black     81395\n",
       "silver    48189\n",
       "blue      34693\n",
       "red       31669\n",
       "grey      30351\n",
       "custom     9000\n",
       "green      8675\n",
       "brown      7061\n",
       "orange     2319\n",
       "yellow     2184\n",
       "purple      755\n",
       "Name: paint_color, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T22:47:10.989837Z",
     "start_time": "2020-07-27T22:47:10.972882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89241"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['paint_color'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T22:46:42.216225Z",
     "start_time": "2020-07-27T22:45:56.095585Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['paint_color'] = df1.apply( lambda x: x['paint_color'] if pd.isna( x['description'] ) or pd.notna( x['paint_color'] )\n",
    "                                else 'white' if 'white' in str(x['description']).split() \n",
    "                                else 'black' if 'black' in str(x['description']).split() \n",
    "                                else 'silver' if 'silver' in str(x['description']).split() \n",
    "                                else 'blue' if 'blue' in str(x['description']).split() \n",
    "                                else 'grey' if 'grey ' in str(x['description']).split() \n",
    "                                else 'red' if 'red' in str(x['description']).split() \n",
    "                                else 'green' if 'green' in str(x['description']).split() \n",
    "                                else 'custom' if 'custom' in str(x['description']).split()\n",
    "                                else 'brown' if 'brown' in str(x['description']).split()\n",
    "                                else 'yellow' if 'yellow' in str(x['description']).split()\n",
    "                                else 'orange' if 'orange' in str(x['description']).split()\n",
    "                                else 'purple' if 'purple' in str(x['description']).split()\n",
    "                                else x['paint_color'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T22:51:53.338651Z",
     "start_time": "2020-07-27T22:51:53.301722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15954</th>\n",
       "      <td>asheville</td>\n",
       "      <td>nc</td>\n",
       "      <td>35.0390</td>\n",
       "      <td>-81.8220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376840</th>\n",
       "      <td>salem</td>\n",
       "      <td>or</td>\n",
       "      <td>44.9732</td>\n",
       "      <td>-123.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294296</th>\n",
       "      <td>corpus christi</td>\n",
       "      <td>tx</td>\n",
       "      <td>27.7036</td>\n",
       "      <td>-97.3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412369</th>\n",
       "      <td>york</td>\n",
       "      <td>pa</td>\n",
       "      <td>39.9707</td>\n",
       "      <td>-76.7058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272062</th>\n",
       "      <td>cincinnati</td>\n",
       "      <td>oh</td>\n",
       "      <td>39.4271</td>\n",
       "      <td>-84.4515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202112</th>\n",
       "      <td>dallas / fort worth</td>\n",
       "      <td>tx</td>\n",
       "      <td>32.9390</td>\n",
       "      <td>-97.2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259563</th>\n",
       "      <td>lewiston / clarkston</td>\n",
       "      <td>id</td>\n",
       "      <td>46.2069</td>\n",
       "      <td>-116.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411680</th>\n",
       "      <td>york</td>\n",
       "      <td>pa</td>\n",
       "      <td>39.5129</td>\n",
       "      <td>-76.9095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415850</th>\n",
       "      <td>wichita</td>\n",
       "      <td>ks</td>\n",
       "      <td>37.6640</td>\n",
       "      <td>-97.4722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169488</th>\n",
       "      <td>sacramento</td>\n",
       "      <td>ca</td>\n",
       "      <td>38.5449</td>\n",
       "      <td>-121.7410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410382</th>\n",
       "      <td>billings</td>\n",
       "      <td>mt</td>\n",
       "      <td>44.7777</td>\n",
       "      <td>-106.9440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96133</th>\n",
       "      <td>boise</td>\n",
       "      <td>id</td>\n",
       "      <td>43.5703</td>\n",
       "      <td>-116.5790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340170</th>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>pa</td>\n",
       "      <td>40.3074</td>\n",
       "      <td>-79.5424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59799</th>\n",
       "      <td>detroit metro</td>\n",
       "      <td>mi</td>\n",
       "      <td>42.6237</td>\n",
       "      <td>-82.8631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253743</th>\n",
       "      <td>flint</td>\n",
       "      <td>mi</td>\n",
       "      <td>43.1700</td>\n",
       "      <td>-83.8900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      region state      lat      long\n",
       "15954              asheville    nc  35.0390  -81.8220\n",
       "376840                 salem    or  44.9732 -123.0180\n",
       "294296        corpus christi    tx  27.7036  -97.3450\n",
       "412369                  york    pa  39.9707  -76.7058\n",
       "272062            cincinnati    oh  39.4271  -84.4515\n",
       "202112   dallas / fort worth    tx  32.9390  -97.2330\n",
       "259563  lewiston / clarkston    id  46.2069 -116.8960\n",
       "411680                  york    pa  39.5129  -76.9095\n",
       "415850               wichita    ks  37.6640  -97.4722\n",
       "169488            sacramento    ca  38.5449 -121.7410\n",
       "410382              billings    mt  44.7777 -106.9440\n",
       "96133                  boise    id  43.5703 -116.5790\n",
       "340170            pittsburgh    pa  40.3074  -79.5424\n",
       "59799          detroit metro    mi  42.6237  -82.8631\n",
       "253743                 flint    mi  43.1700  -83.8900"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['region', 'state', 'lat', 'long']].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
